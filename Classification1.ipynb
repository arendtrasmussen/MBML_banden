{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Classification models  \n",
    "\n",
    "## Part 4: Travel mode choice - Hierarchical models\n",
    "\n",
    "This part is where we start to make things more interesting :-)\n",
    "\n",
    "We will revisit the original real world problem of travel model choice (with 4 classes), but this time we shall consider a hierarchical model. \n",
    "\n",
    "More on that later, for now the same stuff from part 2: imports, loading data, preprocessing, train/test split, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import pystan\n",
    "import pystan_utils\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# fix random generator seed (for reproducibility of results)\n",
    "np.random.seed(42)\n",
    "\n",
    "# matplotlib style options\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop1 = pd.read_csv(\"SpotifyAudioFeatures2017.csv\")\n",
    "pop2 = pd.read_csv(\"SpotifyAudioFeatures2018.csv\")\n",
    "pop3 = pd.read_csv(\"SpotifyAudioFeatures2019.csv\")\n",
    "\n",
    "df_pop = pd.concat([pop1, pop2,pop3])\n",
    "df_pop[\"genre\"] = [1]*len(df_pop)\n",
    "\n",
    "met1 = pd.read_csv(\"SpotifyAudioFeatures2017metal.csv\")\n",
    "met2 = pd.read_csv(\"SpotifyAudioFeatures2018metal.csv\")\n",
    "met3 = pd.read_csv(\"SpotifyAudioFeatures2019metal.csv\")\n",
    "\n",
    "df_met = pd.concat([met1, met2, met3])\n",
    "df_met[\"genre\"] = [2]*len(df_met)\n",
    "\n",
    "df_clas = pd.read_csv(\"SpotifyAudioFeaturesclassical.csv\")\n",
    "df_clas[\"genre\"] = [3]*len(df_clas)\n",
    "\n",
    "rap1 = pd.read_csv(\"SpotifyAudioFeatures2017rap.csv\")\n",
    "rap2 = pd.read_csv(\"SpotifyAudioFeatures2018rap.csv\")\n",
    "rap3 = pd.read_csv(\"SpotifyAudioFeatures2019rap.csv\")\n",
    "\n",
    "df_rap = pd.concat([rap1, rap2, rap3])\n",
    "df_rap[\"genre\"] = [3]*len(df_rap)\n",
    "\n",
    "df = pd.concat([df_pop,df_met,df_clas,df_rap])\n",
    "#df.to_csv(\"genredata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUNMI</td>\n",
       "      <td>Gashina</td>\n",
       "      <td>0jFHMDRXxKaREor3hBEEST</td>\n",
       "      <td>74</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.722</td>\n",
       "      <td>180000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>-3.915</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>93.941</td>\n",
       "      <td>4</td>\n",
       "      <td>0.530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nelson Can</td>\n",
       "      <td>Break Down Your Walls</td>\n",
       "      <td>3r6nuiebZxOtdd9tKhZ5SV</td>\n",
       "      <td>40</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.603</td>\n",
       "      <td>230060</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-8.590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>107.968</td>\n",
       "      <td>4</td>\n",
       "      <td>0.226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>199X</td>\n",
       "      <td>Gillette</td>\n",
       "      <td>5PVPkjFKLElXpshtXtXIFc</td>\n",
       "      <td>58</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>0.608</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>-4.077</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>120.072</td>\n",
       "      <td>4</td>\n",
       "      <td>0.286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Yoke Lore</td>\n",
       "      <td>Truly Madly Deeply - Recorded at Spotify Studi...</td>\n",
       "      <td>0hLObGB9xRjuRVasHehmLI</td>\n",
       "      <td>68</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.675</td>\n",
       "      <td>190393</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>-14.072</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>106.001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Martin Garrix</td>\n",
       "      <td>Byte</td>\n",
       "      <td>20hsdn8oITBsuWNLhzr5eh</td>\n",
       "      <td>63</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.597</td>\n",
       "      <td>285089</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>-4.026</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>128.031</td>\n",
       "      <td>4</td>\n",
       "      <td>0.267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1    artist_name  \\\n",
       "0           0             0          SUNMI   \n",
       "1           1             1     Nelson Can   \n",
       "2           2             2           199X   \n",
       "3           3             3      Yoke Lore   \n",
       "4           4             4  Martin Garrix   \n",
       "\n",
       "                                          track_name                track_id  \\\n",
       "0                                            Gashina  0jFHMDRXxKaREor3hBEEST   \n",
       "1                              Break Down Your Walls  3r6nuiebZxOtdd9tKhZ5SV   \n",
       "2                                           Gillette  5PVPkjFKLElXpshtXtXIFc   \n",
       "3  Truly Madly Deeply - Recorded at Spotify Studi...  0hLObGB9xRjuRVasHehmLI   \n",
       "4                                               Byte  20hsdn8oITBsuWNLhzr5eh   \n",
       "\n",
       "   popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0          74      0.055600         0.722       180000   0.833   \n",
       "1          40      0.632000         0.603       230060   0.551   \n",
       "2          58      0.006350         0.608       120000   0.932   \n",
       "3          68      0.826000         0.675       190393   0.368   \n",
       "4          63      0.000636         0.597       285089   0.931   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
       "0          0.000000    6    0.1950    -3.915     1       0.0940   93.941   \n",
       "1          0.000095    2    0.1110    -8.590     1       0.0398  107.968   \n",
       "2          0.000783    7    0.3320    -4.077     1       0.0855  120.072   \n",
       "3          0.001600    0    0.1360   -14.072     0       0.0374  106.001   \n",
       "4          0.821000    7    0.0593    -4.026     0       0.0329  128.031   \n",
       "\n",
       "   time_signature  valence  genre  \n",
       "0               4    0.530      1  \n",
       "1               4    0.226      1  \n",
       "2               4    0.286      1  \n",
       "3               4    0.176      1  \n",
       "4               4    0.267      1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv\n",
    "df_tracks = pd.read_csv(\"genredata.csv\")\n",
    "df_tracks = df_tracks.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)\n",
    "df_tracks = df_tracks.dropna(axis = 0)\n",
    "df_tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_tracks.groupby(['artist_name','track_name'], as_index=True).size()\n",
    "grouped[grouped > 1].count()\n",
    "df_tracks.drop_duplicates(subset=['artist_name','track_name'], inplace=True)\n",
    "\n",
    "# doing the same grouping as before to verify the solution\n",
    "grouped_after_dropping = df_tracks.groupby(['artist_name','track_name'], as_index=True).size()\n",
    "grouped_after_dropping[grouped_after_dropping > 1].count()\n",
    "\n",
    "df_tracks[df_tracks.duplicated(subset=['artist_name','track_name'],keep=False)].count()\n",
    "df = df_tracks\n",
    "df = shuffle(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13200, 15)\n",
      "(13200,)\n",
      "(13200,)\n"
     ]
    }
   ],
   "source": [
    "# separate between features/inputs (X) and target/output variables (y)\n",
    "mat = df.drop(['artist_name','track_name','track_id'],axis = 1)\n",
    "mat = mat.values\n",
    "X = mat.astype(\"float\")\n",
    "print(X.shape)\n",
    "y = mat[:,-1].astype(\"int\")\n",
    "print(y.shape)\n",
    "ind = mat[:,1].astype(\"int\")\n",
    "print(ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize input features\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 8712\n",
      "num test: 4488\n"
     ]
    }
   ],
   "source": [
    "train_perc = 0.66 # percentage of training data\n",
    "split_point = int(train_perc*len(y))\n",
    "perm = np.random.permutation(len(y))\n",
    "ix_train = perm[:split_point]\n",
    "ix_test = perm[split_point:]\n",
    "X_train = X[ix_train,:]\n",
    "X_test = X[ix_test,:]\n",
    "ind_train = ind[ix_train]\n",
    "ind_test = ind[ix_test]\n",
    "y_train = y[ix_train]\n",
    "y_test = y[ix_test]\n",
    "print(\"num train: %d\" % len(y_train))\n",
    "print(\"num test: %d\" % len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.80856427,  1.13743298, -0.54915804, ...,  0.2814087 ,\n",
       "        -0.04574581,  0.95365832],\n",
       "       [ 1.04139254, -0.76984895,  1.00469329, ...,  0.2814087 ,\n",
       "         0.63759007, -1.10999575],\n",
       "       [ 0.50221152, -1.23803129,  0.2813487 , ...,  0.2814087 ,\n",
       "         0.59691531, -1.10999575],\n",
       "       ...,\n",
       "       [ 1.07990547, -0.62218841,  0.75911334, ...,  0.2814087 ,\n",
       "         0.18203281, -1.10999575],\n",
       "       [ 0.77180203, -0.59265631,  0.98683293, ...,  0.2814087 ,\n",
       "         0.60098279, -1.10999575],\n",
       "       [-1.65451255,  1.10051785, -0.78134272, ...,  0.2814087 ,\n",
       "        -1.05447973,  0.95365832]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline logistic regression model from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [3 3 1 ... 1 3 1]\n",
      "True values: [3 3 1 ... 1 3 1]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# create and fit logistic regression model\n",
    "logreg = linear_model.LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test set\n",
    "y_hat = logreg.predict(X_test)\n",
    "print(\"Predictions:\", y_hat)\n",
    "print(\"True values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical logistic regression in STAN\n",
    "\n",
    "We will now implement a hierarchical logistic regression. The motivation is actually quite simple. Our dataset consists of multiple observations from various individuals. However, when we build our original logistic regression in STAN, our specification assumes that all individuals share a unique set of bias (alpha) coefficients (beta). In other words, this is equivalent to assuming, for example, that all individuals are equally biased towards a given mode (e.g. car). This is obviously a very strong assumption, right? We should allow different individuals to have different biases (alpha). (We could also consider different coefficients per individual, but for the sake of simplicy, we will just focus on the bias parameters)\n",
    "\n",
    "This can be done by placing a hierarchical prior on the intercepts (alpha). The generative process then becomes:\n",
    "\n",
    "1. For each class $c \\in \\{1,\\dots,C\\}$\n",
    "    2. Draw global intercept mean $\\mu_c \\sim \\mathcal{N}(0,10)$\n",
    "    3. Draw global intercept variance $\\sigma_c \\sim \\mbox{Cauchy}(0,10)$\n",
    "    5. Draw coefficients $\\boldsymbol\\beta_c \\sim \\mathcal{N}(\\textbf{0},10 \\, \\textbf{I})$ (this the same as before...)\n",
    "    6. For each individual $i \\in \\{1,\\dots,I\\}$\n",
    "        4. Draw $\\alpha_{i,c}$ such that $\\alpha_{i,c} \\sim \\mathcal{N}(\\mu_c,\\sigma_c)$\n",
    "\n",
    "6. For each data point $n=\\{1,\\dots,N\\}$\n",
    "    7. Draw target class $y_n \\sim \\mbox{Multinomial}(\\mbox{Softmax}(\\textbf{x}_n,\\boldsymbol\\alpha_{i_n},\\boldsymbol\\beta_1,\\dots,\\boldsymbol\\beta_C))$\n",
    "    \n",
    "where $i_n$ is the individual identifier for person $n$, and $\\boldsymbol\\mu=\\{\\mu_1\\dots\\mu_C\\}$ and $\\boldsymbol\\sigma=\\{\\sigma_1\\dots\\sigma_C\\}$.\n",
    "\n",
    "Notice that now, instead of a single intercept per class $\\alpha_c$ for all individual, we now have a vector of intercepts $\\boldsymbol\\alpha_c$ for each class $c$: one intercept parameter per individual! However, all these intercept share a global (population-level) prior.\n",
    "\n",
    "Lets try to implement this in STAN. Can you do it? :-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Stan model\n",
    "model_definition = \"\"\"\n",
    "data {\n",
    "    int<lower=0> N;\n",
    "    int<lower=1> D;\n",
    "    int<lower=1> C;\n",
    "    int<lower=1> I;\n",
    "    int ind[N];\n",
    "    matrix[N,D] X;\n",
    "    int<lower=0,upper = C> y[N];\n",
    "}\n",
    "parameters {\n",
    "    matrix[C,D] beta;\n",
    "    matrix[I,C] alpha; // i individer og c classes, intercept/bias for hver class, 4 intercepts for hver\n",
    "    \n",
    "    vector[C] mu_prior;\n",
    "    vector<lower=0>[C] sigma_prior;\n",
    "    \n",
    "}\n",
    "\n",
    "model {\n",
    "    for(c in 1:C){\n",
    "        mu_prior[c] ~ normal(0,1);\n",
    "        sigma_prior[c] ~ normal(0,1);\n",
    "        beta[c] ~ normal(0,1);\n",
    "        \n",
    "        for(i in 1:I){\n",
    "            alpha[i,c] ~ normal(mu_prior[c],sigma_prior[c]);\n",
    "        }\n",
    "    }\n",
    "    for(n in 1:N){\n",
    "        y[n] ~ categorical(softmax(alpha[ind[n],:]' + beta*X[n]'));\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input data for STAN, compile STAN program and run inference using ADVI (much faster in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 8712, D = 15, C = 3, I = 0\n"
     ]
    }
   ],
   "source": [
    "# prepare data for Stan model\n",
    "N, D = X_train.shape\n",
    "C = int(y_train.max())\n",
    "I = ind.max()\n",
    "print(\"N = %d, D = %d, C = %d, I = %d\" % (N,D,C,I))\n",
    "data = {'N': N, 'D': D, 'C': C, 'I':I, 'ind':ind_train, 'X': X_train, 'y': y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_47fb036e992c954f28293ae82a359042 NOW.\n",
      "C:\\Users\\clara\\Anaconda3\\lib\\site-packages\\Cython\\Compiler\\Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\clara\\AppData\\Local\\Temp\\tmpzoe38xa7\\stanfit4anon_model_47fb036e992c954f28293ae82a359042_7670231639174555707.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "C:\\Users\\clara\\Anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception: anon_model_47fb036e992c954f28293ae82a359042_namespace::anon_model_47fb036e992c954f28293ae82a359042: I is 0, but must be greater than or equal to 1  (in 'unknown file name' at line 6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pystan\\model.py\u001b[0m in \u001b[0;36mvb\u001b[1;34m(self, data, pars, iter, seed, init, sample_file, diagnostic_file, verbose, algorithm, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Algorithm must be one of {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m         \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m         \u001b[0mm_pars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[0mp_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mstanfit4anon_model_47fb036e992c954f28293ae82a359042_7670231639174555707.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_47fb036e992c954f28293ae82a359042_7670231639174555707.StanFit4Model.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception: anon_model_47fb036e992c954f28293ae82a359042_namespace::anon_model_47fb036e992c954f28293ae82a359042: I is 0, but must be greater than or equal to 1  (in 'unknown file name' at line 6)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create Stan model object\n",
    "sm = pystan.StanModel(model_code=model_definition)\n",
    "fit = sm.vb(data=data, iter=10000, algorithm=\"meanfield\", grad_samples=10, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the posterior distributions of some of the parameters of our model (you may have called these variables something else...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-ed2ed6d5f844>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpystan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvb_plot_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mu_prior\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#mu_prior\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Hyper-priors for each class for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "pystan_utils.vb_plot_variables(fit, \"mu_prior\") #mu_prior\n",
    "# Hyper-priors for each class for all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pystan_utils.vb_plot_variables(fit, \"sigma_prior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the inferred posteriors to make predictions. Lets first use the \"pystan_utils\" package to extract the expected values of the posterior distribution of the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fitted parameters\n",
    "mu_prior = pystan_utils.vb_extract_variable(fit, \"mu_prior\", var_type=\"vector\")\n",
    "sigma_prior = pystan_utils.vb_extract_variable(fit, \"sigma_prior\", var_type=\"vector\")\n",
    "alpha = pystan_utils.vb_extract_variable(fit, \"alpha\", var_type=\"matrix\", dims=(C,I))\n",
    "beta = pystan_utils.vb_extract_variable(fit, \"beta\", var_type=\"matrix\", dims=(C,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using expected values of the parameters, we can make predictions for the testset. However, we need to account for the fact that we now have different bias parameters per-individual, and adapt the code for making predictions accordingly. Make sure that you understand the code below. As always, if something is not 100% clear, ask! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test set\n",
    "y_hat = alpha[:,ind_test-1] + np.dot(beta, X_test.T)\n",
    "y_hat = np.argmax(y_hat, axis=0) + 1\n",
    "print(\"predictions:\", y_hat)\n",
    "print(\"true values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that is a signficant improvement, right? We improved the accuracy of our model from 67.9% to about 78.4%! (Hopefully you were able to obtain a similar or even better result :-)\n",
    "\n",
    "Did you see how your prior knowledge about the problem can make a substantial difference when building a model for it? This is how things are done in the model-based machine learning approach!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the posterior distributions inferred by STAN, we can even analyse the biases of different individuals identified by our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(I):\n",
    "    print(i, alpha[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps a histogram allows for a better global analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of biases towards mode 4 (car)\n",
    "plt.hist(alpha[3,:])\n",
    "plt.title(\"Biases towards mode 4\")\n",
    "plt.xlabel(\"alpha[4]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that, for most individuals the biases is around 0. However, we can also see that a few individuals really love their cars!\n",
    "\n",
    "Reflection exercise: can you think of ways in which you could use this model to try to identify policies (e.g. price changes or making terminals more efficient) that would allow to shift people's travel mode choices away from the car (e.g. towards public transport)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
