{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of genre - logistic regression and hierarchical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import pystan\n",
    "import pystan_utils\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# fix random generator seed (for reproducibility of results)\n",
    "np.random.seed(42)\n",
    "\n",
    "# matplotlib style options\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### pop = 1 ####\n",
    "pop1 = pd.read_csv(\"SpotifyAudioFeatures2017.csv\")\n",
    "pop2 = pd.read_csv(\"SpotifyAudioFeatures2018.csv\")\n",
    "pop3 = pd.read_csv(\"SpotifyAudioFeatures2019.csv\")\n",
    "df_pop = pd.concat([pop1, pop2,pop3])\n",
    "df_pop[\"genre\"] = [1]*len(df_pop)\n",
    "\n",
    "#### metal = 2 ####\n",
    "met1 = pd.read_csv(\"SpotifyAudioFeatures2017metal.csv\")\n",
    "met2 = pd.read_csv(\"SpotifyAudioFeatures2018metal.csv\")\n",
    "met3 = pd.read_csv(\"SpotifyAudioFeatures2019metal.csv\")\n",
    "#df_met = pd.concat([met1, met2, met3])\n",
    "df_met = pd.read_csv(\"SpotifyAudioFeatures201720182019metal.csv\")\n",
    "df_met[\"genre\"] = [2]*len(df_met)\n",
    "\n",
    "#### classical = 3 ####\n",
    "df_clas = pd.read_csv(\"SpotifyAudioFeaturesclassical.csv\")\n",
    "df_clas[\"genre\"] = [3]*len(df_clas)\n",
    "\n",
    "#### rap = 4 ####\n",
    "rap1 = pd.read_csv(\"SpotifyAudioFeatures2017rap.csv\")\n",
    "rap2 = pd.read_csv(\"SpotifyAudioFeatures2018rap.csv\")\n",
    "rap3 = pd.read_csv(\"SpotifyAudioFeatures2019rap.csv\")\n",
    "#df_rap = pd.concat([rap1, rap2, rap3])\n",
    "df_rap = pd.read_csv(\"SpotifyAudioFeatures201720182019rap.csv\")\n",
    "df_rap[\"genre\"] = [4]*len(df_rap)\n",
    "\n",
    "df = pd.concat([df_rap,df_met,df_clas,df_pop])\n",
    "#df.to_csv(\"genredata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pop (1):  (6018, 19)\n",
      "Shape of metal (2):  (4481, 19)\n",
      "Shape of classical (3):  (5040, 19)\n",
      "Shape of rap (4):  (2786, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of pop (1): \", df_pop.shape)\n",
    "print(\"Shape of metal (2): \", df_met.shape)\n",
    "print(\"Shape of classical (3): \", df_clas.shape) \n",
    "print(\"Shape of rap (4): \",df_rap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load csv\n",
    "df_tracks = pd.read_csv(\"genredata.csv\")\n",
    "df_tracks = df\n",
    "#df_tracks = df_tracks.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)\n",
    "df_tracks = df_tracks.dropna(axis = 0)\n",
    "df_tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16764, 19)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_tracks = shuffle(df_tracks)\n",
    "grouped = df_tracks.groupby(['artist_name','track_name'], as_index=True).size()\n",
    "grouped[grouped > 1].count()\n",
    "df_tracks.drop_duplicates(subset=['artist_name','track_name'], inplace=True)\n",
    "\n",
    "# doing the same grouping as before to verify the solution\n",
    "grouped_after_dropping = df_tracks.groupby(['artist_name','track_name'], as_index=True).size()\n",
    "grouped_after_dropping[grouped_after_dropping > 1].count()\n",
    "\n",
    "df_tracks[df_tracks.duplicated(subset=['artist_name','track_name'],keep=False)].count()\n",
    "df = df_tracks\n",
    "#df = shuffle(df)\n",
    "df.shape\n",
    "#ind = df[\"Unnamed: 0\"]\n",
    "#df.to_csv(\"genredata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['genre'])\n",
    "plt.ylabel('Count')\n",
    "plt.title('Genre frequency')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16764, 13)\n",
      "(16764,)\n",
      "(16764,)\n"
     ]
    }
   ],
   "source": [
    "# separate between features/inputs (X) and target/output variables (y)\n",
    "mat = df.drop(['artist_name','track_name','track_id'],axis = 1)\n",
    "mat = mat.values\n",
    "X = mat[:,2:-1].astype(\"float\")\n",
    "print(X.shape)\n",
    "y = mat[:,-1].astype(\"int\")\n",
    "print(y.shape)\n",
    "ind = mat[:,0].astype(\"int\")\n",
    "print(ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize input features\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 11064\n",
      "num test: 5700\n"
     ]
    }
   ],
   "source": [
    "train_perc = 0.66 # percentage of training data\n",
    "split_point = int(train_perc*len(y))\n",
    "perm = np.random.permutation(len(y))\n",
    "ix_train = perm[:split_point]\n",
    "ix_test = perm[split_point:]\n",
    "X_train = X[ix_train,:]\n",
    "X_test = X[ix_test,:]\n",
    "ind_train = ind[ix_train]\n",
    "ind_test = ind[ix_test]\n",
    "y_train = y[ix_train]\n",
    "y_test = y[ix_test]\n",
    "print(\"num train: %d\" % len(y_train))\n",
    "print(\"num test: %d\" % len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1937, 10597,  2873, ...,  6771, 14701,  3219])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline logistic regression model from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [2 1 2 ... 3 1 3]\n",
      "True values: [2 4 2 ... 3 1 3]\n",
      "Accuracy: 0.7924561403508772\n"
     ]
    }
   ],
   "source": [
    "# create and fit logistic regression model\n",
    "logreg = linear_model.LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test set\n",
    "y_hat = logreg.predict(X_test)\n",
    "print(\"Predictions:\", y_hat)\n",
    "print(\"True values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical logistic regression in STAN\n",
    "\n",
    "We will now implement a hierarchical logistic regression. The motivation is actually quite simple. Our dataset consists of multiple observations from various individuals. However, when we build our original logistic regression in STAN, our specification assumes that all individuals share a unique set of bias (alpha) coefficients (beta). In other words, this is equivalent to assuming, for example, that all individuals are equally biased towards a given mode (e.g. car). This is obviously a very strong assumption, right? We should allow different individuals to have different biases (alpha). (We could also consider different coefficients per individual, but for the sake of simplicy, we will just focus on the bias parameters)\n",
    "\n",
    "This can be done by placing a hierarchical prior on the intercepts (alpha). The generative process then becomes:\n",
    "\n",
    "1. For each class $c \\in \\{1,\\dots,C\\}$\n",
    "    2. Draw global intercept mean $\\mu_c \\sim \\mathcal{N}(0,10)$\n",
    "    3. Draw global intercept variance $\\sigma_c \\sim \\mbox{Cauchy}(0,10)$\n",
    "    5. Draw coefficients $\\boldsymbol\\beta_c \\sim \\mathcal{N}(\\textbf{0},10 \\, \\textbf{I})$ (this the same as before...)\n",
    "    6. For each individual $i \\in \\{1,\\dots,I\\}$\n",
    "        4. Draw $\\alpha_{i,c}$ such that $\\alpha_{i,c} \\sim \\mathcal{N}(\\mu_c,\\sigma_c)$\n",
    "\n",
    "6. For each data point $n=\\{1,\\dots,N\\}$\n",
    "    7. Draw target class $y_n \\sim \\mbox{Multinomial}(\\mbox{Softmax}(\\textbf{x}_n,\\boldsymbol\\alpha_{i_n},\\boldsymbol\\beta_1,\\dots,\\boldsymbol\\beta_C))$\n",
    "    \n",
    "where $i_n$ is the individual identifier for person $n$, and $\\boldsymbol\\mu=\\{\\mu_1\\dots\\mu_C\\}$ and $\\boldsymbol\\sigma=\\{\\sigma_1\\dots\\sigma_C\\}$.\n",
    "\n",
    "Notice that now, instead of a single intercept per class $\\alpha_c$ for all individual, we now have a vector of intercepts $\\boldsymbol\\alpha_c$ for each class $c$: one intercept parameter per individual! However, all these intercept share a global (population-level) prior.\n",
    "\n",
    "Lets try to implement this in STAN. Can you do it? :-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Stan model\n",
    "model_definition = \"\"\"\n",
    "data {\n",
    "    int<lower=0> N;\n",
    "    int<lower=1> D;\n",
    "    int<lower=1> C;\n",
    "    int<lower=1> I;\n",
    "    int ind[N];\n",
    "    matrix[N,D] X;\n",
    "    int<lower=0,upper = C> y[N];\n",
    "}\n",
    "parameters {\n",
    "    matrix[C,D] beta;\n",
    "    matrix[I,C] alpha; // i individer og c classes, intercept/bias for hver class, 4 intercepts for hver\n",
    "    \n",
    "    vector[C] mu_prior;\n",
    "    vector<lower=0>[C] sigma_prior;\n",
    "    \n",
    "}\n",
    "\n",
    "model {\n",
    "    for(c in 1:C){\n",
    "        mu_prior[c] ~ normal(0,1);\n",
    "        sigma_prior[c] ~ normal(0,1);\n",
    "        beta[c] ~ normal(0,1);\n",
    "        \n",
    "        for(i in 1:I){\n",
    "            alpha[i,c] ~ normal(mu_prior[c],sigma_prior[c]);\n",
    "        }\n",
    "    }\n",
    "    for(n in 1:N){\n",
    "        y[n] ~ categorical(softmax(alpha[ind[n],:]' + beta*X[n]'));\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input data for STAN, compile STAN program and run inference using ADVI (much faster in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 11064, D = 16, C = 4, I = 100\n"
     ]
    }
   ],
   "source": [
    "# prepare data for Stan model\n",
    "N, D = X_train.shape\n",
    "C = int(y_train.max())\n",
    "I = ind.max()\n",
    "print(\"N = %d, D = %d, C = %d, I = %d\" % (N,D,C,I))\n",
    "data = {'N': N, 'D': D, 'C': C, 'I':I, 'ind':ind_train, 'X': X_train, 'y': y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_47fb036e992c954f28293ae82a359042 NOW.\n",
      "C:\\Users\\clara\\Anaconda3\\lib\\site-packages\\Cython\\Compiler\\Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\clara\\AppData\\Local\\Temp\\tmpkqxi5i8_\\stanfit4anon_model_47fb036e992c954f28293ae82a359042_1659035022966619179.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "C:\\Users\\clara\\Anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception: matrix[uni,multi] indexing, row: accessing element out of range. index 0 out of range; expecting index to be between 1 and 100  (in 'unknown file name' at line 31)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pystan\\model.py\u001b[0m in \u001b[0;36mvb\u001b[1;34m(self, data, pars, iter, seed, init, sample_file, diagnostic_file, verbose, algorithm, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[0mstan_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_valid_stan_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstan_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_sampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstan_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Automatic Differentiation Variational Inference (ADVI) is an EXPERIMENTAL ALGORITHM.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mstanfit4anon_model_47fb036e992c954f28293ae82a359042_1659035022966619179.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_47fb036e992c954f28293ae82a359042_1659035022966619179.StanFit4Model._call_sampler\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mstanfit4anon_model_47fb036e992c954f28293ae82a359042_1659035022966619179.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_47fb036e992c954f28293ae82a359042_1659035022966619179._call_sampler\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exception: matrix[uni,multi] indexing, row: accessing element out of range. index 0 out of range; expecting index to be between 1 and 100  (in 'unknown file name' at line 31)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create Stan model object\n",
    "sm = pystan.StanModel(model_code=model_definition)\n",
    "fit = sm.vb(data=data, iter=10000, algorithm=\"meanfield\", grad_samples=10, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the posterior distributions of some of the parameters of our model (you may have called these variables something else...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ed2ed6d5f844>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpystan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvb_plot_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mu_prior\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#mu_prior\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Hyper-priors for each class for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "pystan_utils.vb_plot_variables(fit, \"mu_prior\") #mu_prior\n",
    "# Hyper-priors for each class for all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pystan_utils.vb_plot_variables(fit, \"sigma_prior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the inferred posteriors to make predictions. Lets first use the \"pystan_utils\" package to extract the expected values of the posterior distribution of the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fitted parameters\n",
    "mu_prior = pystan_utils.vb_extract_variable(fit, \"mu_prior\", var_type=\"vector\")\n",
    "sigma_prior = pystan_utils.vb_extract_variable(fit, \"sigma_prior\", var_type=\"vector\")\n",
    "alpha = pystan_utils.vb_extract_variable(fit, \"alpha\", var_type=\"matrix\", dims=(C,I))\n",
    "beta = pystan_utils.vb_extract_variable(fit, \"beta\", var_type=\"matrix\", dims=(C,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using expected values of the parameters, we can make predictions for the testset. However, we need to account for the fact that we now have different bias parameters per-individual, and adapt the code for making predictions accordingly. Make sure that you understand the code below. As always, if something is not 100% clear, ask! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test set\n",
    "y_hat = alpha[:,ind_test-1] + np.dot(beta, X_test.T)\n",
    "y_hat = np.argmax(y_hat, axis=0) + 1\n",
    "print(\"predictions:\", y_hat)\n",
    "print(\"true values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that is a signficant improvement, right? We improved the accuracy of our model from 67.9% to about 78.4%! (Hopefully you were able to obtain a similar or even better result :-)\n",
    "\n",
    "Did you see how your prior knowledge about the problem can make a substantial difference when building a model for it? This is how things are done in the model-based machine learning approach!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the posterior distributions inferred by STAN, we can even analyse the biases of different individuals identified by our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(I):\n",
    "    print(i, alpha[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps a histogram allows for a better global analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of biases towards mode 4 (car)\n",
    "plt.hist(alpha[3,:])\n",
    "plt.title(\"Biases towards mode 4\")\n",
    "plt.xlabel(\"alpha[4]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that, for most individuals the biases is around 0. However, we can also see that a few individuals really love their cars!\n",
    "\n",
    "Reflection exercise: can you think of ways in which you could use this model to try to identify policies (e.g. price changes or making terminals more efficient) that would allow to shift people's travel mode choices away from the car (e.g. towards public transport)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
