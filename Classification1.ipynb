{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of genre - logistic regression and hierarchical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import pystan\n",
    "import pystan_utils\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# fix random generator seed (for reproducibility of results)\n",
    "np.random.seed(42)\n",
    "\n",
    "# matplotlib style options\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### pop = 1 ####\n",
    "pop1 = pd.read_csv(\"SpotifyAudioFeatures2017.csv\")\n",
    "pop2 = pd.read_csv(\"SpotifyAudioFeatures2018.csv\")\n",
    "pop3 = pd.read_csv(\"SpotifyAudioFeatures2019.csv\")\n",
    "df_pop = pd.concat([pop1, pop2,pop3])\n",
    "df_pop[\"genre\"] = [1]*len(df_pop)\n",
    "\n",
    "#### metal = 2 ####\n",
    "met1 = pd.read_csv(\"SpotifyAudioFeatures2017metal.csv\")\n",
    "met2 = pd.read_csv(\"SpotifyAudioFeatures2018metal.csv\")\n",
    "met3 = pd.read_csv(\"SpotifyAudioFeatures2019metal.csv\")\n",
    "#df_met = pd.concat([met1, met2, met3])\n",
    "df_met = pd.read_csv(\"SpotifyAudioFeatures201720182019metal.csv\")\n",
    "df_met[\"genre\"] = [2]*len(df_met)\n",
    "\n",
    "#### classical = 3 ####\n",
    "df_clas = pd.read_csv(\"SpotifyAudioFeaturesclassical.csv\")\n",
    "df_clas[\"genre\"] = [3]*len(df_clas)\n",
    "\n",
    "#### rap = 4 ####\n",
    "rap1 = pd.read_csv(\"SpotifyAudioFeatures2017rap.csv\")\n",
    "rap2 = pd.read_csv(\"SpotifyAudioFeatures2018rap.csv\")\n",
    "rap3 = pd.read_csv(\"SpotifyAudioFeatures2019rap.csv\")\n",
    "#df_rap = pd.concat([rap1, rap2, rap3])\n",
    "df_rap = pd.read_csv(\"SpotifyAudioFeatures201720182019rap.csv\")\n",
    "df_rap[\"genre\"] = [4]*len(df_rap)\n",
    "\n",
    "df = pd.concat([df_rap,df_met,df_clas,df_pop])\n",
    "#df.to_csv(\"genredata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pop (1):  (6018, 19)\n",
      "Shape of metal (2):  (4481, 19)\n",
      "Shape of classical (3):  (5040, 19)\n",
      "Shape of rap (4):  (2786, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of pop (1): \", df_pop.shape)\n",
    "print(\"Shape of metal (2): \", df_met.shape)\n",
    "print(\"Shape of classical (3): \", df_clas.shape) \n",
    "print(\"Shape of rap (4): \",df_rap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "      <td>Green Lights</td>\n",
       "      <td>0MvqSYPr5Wi62JB7VWvqwz</td>\n",
       "      <td>67</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.725</td>\n",
       "      <td>181867</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>-4.537</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2460</td>\n",
       "      <td>160.062</td>\n",
       "      <td>4</td>\n",
       "      <td>0.560</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Huncho Jack</td>\n",
       "      <td>Motorcycle Patches</td>\n",
       "      <td>7g7raxdQpiLZT7aOlib4S1</td>\n",
       "      <td>71</td>\n",
       "      <td>0.01580</td>\n",
       "      <td>0.870</td>\n",
       "      <td>191410</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>-5.081</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>162.835</td>\n",
       "      <td>4</td>\n",
       "      <td>0.416</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mobb Deep</td>\n",
       "      <td>Survival of the Fittest</td>\n",
       "      <td>7N1Vjtzr1lmmCW9iasQ8YO</td>\n",
       "      <td>71</td>\n",
       "      <td>0.12500</td>\n",
       "      <td>0.813</td>\n",
       "      <td>224533</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>11</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>-5.077</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2680</td>\n",
       "      <td>94.828</td>\n",
       "      <td>4</td>\n",
       "      <td>0.241</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Macklemore</td>\n",
       "      <td>Marmalade (feat. Lil Yachty)</td>\n",
       "      <td>7bsnTsbiwOymZWjPF9v6Di</td>\n",
       "      <td>70</td>\n",
       "      <td>0.00980</td>\n",
       "      <td>0.922</td>\n",
       "      <td>261615</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>-4.982</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>136.043</td>\n",
       "      <td>4</td>\n",
       "      <td>0.494</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Linkin Park</td>\n",
       "      <td>Papercut</td>\n",
       "      <td>1Vej0qeQ3ioKwpI6FUbRv1</td>\n",
       "      <td>74</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.524</td>\n",
       "      <td>184867</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6230</td>\n",
       "      <td>-3.994</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>150.184</td>\n",
       "      <td>4</td>\n",
       "      <td>0.661</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  artist_name                    track_name  \\\n",
       "0           0           NF                  Green Lights   \n",
       "1           1  Huncho Jack            Motorcycle Patches   \n",
       "2           2    Mobb Deep       Survival of the Fittest   \n",
       "3           3   Macklemore  Marmalade (feat. Lil Yachty)   \n",
       "4           4  Linkin Park                      Papercut   \n",
       "\n",
       "                 track_id  popularity  acousticness  danceability  \\\n",
       "0  0MvqSYPr5Wi62JB7VWvqwz          67       0.13900         0.725   \n",
       "1  7g7raxdQpiLZT7aOlib4S1          71       0.01580         0.870   \n",
       "2  7N1Vjtzr1lmmCW9iasQ8YO          71       0.12500         0.813   \n",
       "3  7bsnTsbiwOymZWjPF9v6Di          70       0.00980         0.922   \n",
       "4  1Vej0qeQ3ioKwpI6FUbRv1          74       0.00022         0.524   \n",
       "\n",
       "   duration_ms  energy  instrumentalness  key  liveness  loudness  mode  \\\n",
       "0       181867   0.659          0.000000    9    0.1060    -4.537     1   \n",
       "1       191410   0.656          0.000000    8    0.1060    -5.081     1   \n",
       "2       224533   0.703          0.000001   11    0.2370    -5.077     0   \n",
       "3       261615   0.583          0.000000    5    0.0962    -4.982     1   \n",
       "4       184867   0.939          0.000000    9    0.6230    -3.994     1   \n",
       "\n",
       "   speechiness    tempo  time_signature  valence  genre  \n",
       "0       0.2460  160.062               4    0.560      4  \n",
       "1       0.1170  162.835               4    0.416      4  \n",
       "2       0.2680   94.828               4    0.241      4  \n",
       "3       0.0753  136.043               4    0.494      4  \n",
       "4       0.1130  150.184               4    0.661      4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv\n",
    "#df_tracks = pd.read_csv(\"genredata.csv\")\n",
    "df_tracks = df\n",
    "#df_tracks = df_tracks.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)\n",
    "df_tracks = df_tracks.dropna(axis = 0)\n",
    "df_tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16764, 19)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_tracks = shuffle(df_tracks)\n",
    "grouped = df_tracks.groupby(['artist_name','track_name'], as_index=True).size()\n",
    "grouped[grouped > 1].count()\n",
    "df_tracks.drop_duplicates(subset=['artist_name','track_name'], inplace=True)\n",
    "\n",
    "# doing the same grouping as before to verify the solution\n",
    "grouped_after_dropping = df_tracks.groupby(['artist_name','track_name'], as_index=True).size()\n",
    "grouped_after_dropping[grouped_after_dropping > 1].count()\n",
    "\n",
    "df_tracks[df_tracks.duplicated(subset=['artist_name','track_name'],keep=False)].count()\n",
    "df = df_tracks\n",
    "df = shuffle(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"genredata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['genre'])\n",
    "plt.ylabel('Count')\n",
    "plt.title('Genre frequency')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16946, 16)\n",
      "(16946,)\n",
      "(16946,)\n"
     ]
    }
   ],
   "source": [
    "# separate between features/inputs (X) and target/output variables (y)\n",
    "mat = df.drop(['artist_name','track_name','track_id'],axis = 1)\n",
    "mat = mat.values\n",
    "X = mat.astype(\"float\")\n",
    "print(X.shape)\n",
    "y = mat[:,-1].astype(\"int\")\n",
    "print(y.shape)\n",
    "ind = mat[:,1].astype(\"int\")\n",
    "print(ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize input features\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 11184\n",
      "num test: 5762\n"
     ]
    }
   ],
   "source": [
    "train_perc = 0.66 # percentage of training data\n",
    "split_point = int(train_perc*len(y))\n",
    "perm = np.random.permutation(len(y))\n",
    "ix_train = perm[:split_point]\n",
    "ix_test = perm[split_point:]\n",
    "X_train = X[ix_train,:]\n",
    "X_test = X[ix_test,:]\n",
    "ind_train = ind[ix_train]\n",
    "ind_test = ind[ix_test]\n",
    "y_train = y[ix_train]\n",
    "y_test = y[ix_test]\n",
    "print(\"num train: %d\" % len(y_train))\n",
    "print(\"num test: %d\" % len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4120837 , -1.54300919,  1.43526218, ...,  0.270733  ,\n",
       "        -0.27138852,  0.81015444],\n",
       "       [-1.30013856,  0.1542601 , -0.96057374, ...,  0.270733  ,\n",
       "        -1.19186015, -0.16929032],\n",
       "       [ 0.74372246, -1.92489478,  1.38186388, ...,  0.270733  ,\n",
       "        -1.2724916 ,  0.81015444],\n",
       "       ...,\n",
       "       [-0.86200009,  0.70587263, -0.73028146, ...,  0.270733  ,\n",
       "        -1.01829035, -1.14873507],\n",
       "       [ 0.32442865,  0.74830436, -0.89581617, ...,  0.270733  ,\n",
       "         1.18422129, -1.14873507],\n",
       "       [ 1.44490105, -1.37328226,  1.42069901, ...,  2.28294417,\n",
       "        -1.2618822 ,  0.81015444]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline logistic regression model from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [3 3 2 ... 1 3 1]\n",
      "True values: [3 3 2 ... 1 3 1]\n",
      "Accuracy: 0.9996528982992017\n"
     ]
    }
   ],
   "source": [
    "# create and fit logistic regression model\n",
    "logreg = linear_model.LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test set\n",
    "y_hat = logreg.predict(X_test)\n",
    "print(\"Predictions:\", y_hat)\n",
    "print(\"True values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical logistic regression in STAN\n",
    "\n",
    "We will now implement a hierarchical logistic regression. The motivation is actually quite simple. Our dataset consists of multiple observations from various individuals. However, when we build our original logistic regression in STAN, our specification assumes that all individuals share a unique set of bias (alpha) coefficients (beta). In other words, this is equivalent to assuming, for example, that all individuals are equally biased towards a given mode (e.g. car). This is obviously a very strong assumption, right? We should allow different individuals to have different biases (alpha). (We could also consider different coefficients per individual, but for the sake of simplicy, we will just focus on the bias parameters)\n",
    "\n",
    "This can be done by placing a hierarchical prior on the intercepts (alpha). The generative process then becomes:\n",
    "\n",
    "1. For each class $c \\in \\{1,\\dots,C\\}$\n",
    "    2. Draw global intercept mean $\\mu_c \\sim \\mathcal{N}(0,10)$\n",
    "    3. Draw global intercept variance $\\sigma_c \\sim \\mbox{Cauchy}(0,10)$\n",
    "    5. Draw coefficients $\\boldsymbol\\beta_c \\sim \\mathcal{N}(\\textbf{0},10 \\, \\textbf{I})$ (this the same as before...)\n",
    "    6. For each individual $i \\in \\{1,\\dots,I\\}$\n",
    "        4. Draw $\\alpha_{i,c}$ such that $\\alpha_{i,c} \\sim \\mathcal{N}(\\mu_c,\\sigma_c)$\n",
    "\n",
    "6. For each data point $n=\\{1,\\dots,N\\}$\n",
    "    7. Draw target class $y_n \\sim \\mbox{Multinomial}(\\mbox{Softmax}(\\textbf{x}_n,\\boldsymbol\\alpha_{i_n},\\boldsymbol\\beta_1,\\dots,\\boldsymbol\\beta_C))$\n",
    "    \n",
    "where $i_n$ is the individual identifier for person $n$, and $\\boldsymbol\\mu=\\{\\mu_1\\dots\\mu_C\\}$ and $\\boldsymbol\\sigma=\\{\\sigma_1\\dots\\sigma_C\\}$.\n",
    "\n",
    "Notice that now, instead of a single intercept per class $\\alpha_c$ for all individual, we now have a vector of intercepts $\\boldsymbol\\alpha_c$ for each class $c$: one intercept parameter per individual! However, all these intercept share a global (population-level) prior.\n",
    "\n",
    "Lets try to implement this in STAN. Can you do it? :-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Stan model\n",
    "model_definition = \"\"\"\n",
    "data {\n",
    "    int<lower=0> N;\n",
    "    int<lower=1> D;\n",
    "    int<lower=1> C;\n",
    "    int<lower=1> I;\n",
    "    int ind[N];\n",
    "    matrix[N,D] X;\n",
    "    int<lower=0,upper = C> y[N];\n",
    "}\n",
    "parameters {\n",
    "    matrix[C,D] beta;\n",
    "    matrix[I,C] alpha; // i individer og c classes, intercept/bias for hver class, 4 intercepts for hver\n",
    "    \n",
    "    vector[C] mu_prior;\n",
    "    vector<lower=0>[C] sigma_prior;\n",
    "    \n",
    "}\n",
    "\n",
    "model {\n",
    "    for(c in 1:C){\n",
    "        mu_prior[c] ~ normal(0,1);\n",
    "        sigma_prior[c] ~ normal(0,1);\n",
    "        beta[c] ~ normal(0,1);\n",
    "        \n",
    "        for(i in 1:I){\n",
    "            alpha[i,c] ~ normal(mu_prior[c],sigma_prior[c]);\n",
    "        }\n",
    "    }\n",
    "    for(n in 1:N){\n",
    "        y[n] ~ categorical(softmax(alpha[ind[n],:]' + beta*X[n]'));\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input data for STAN, compile STAN program and run inference using ADVI (much faster in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 8712, D = 15, C = 3, I = 0\n"
     ]
    }
   ],
   "source": [
    "# prepare data for Stan model\n",
    "N, D = X_train.shape\n",
    "C = int(y_train.max())\n",
    "I = ind.max()\n",
    "print(\"N = %d, D = %d, C = %d, I = %d\" % (N,D,C,I))\n",
    "data = {'N': N, 'D': D, 'C': C, 'I':I, 'ind':ind_train, 'X': X_train, 'y': y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_47fb036e992c954f28293ae82a359042 NOW.\n",
      "C:\\Users\\clara\\Anaconda3\\lib\\site-packages\\Cython\\Compiler\\Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\clara\\AppData\\Local\\Temp\\tmpzoe38xa7\\stanfit4anon_model_47fb036e992c954f28293ae82a359042_7670231639174555707.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "C:\\Users\\clara\\Anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception: anon_model_47fb036e992c954f28293ae82a359042_namespace::anon_model_47fb036e992c954f28293ae82a359042: I is 0, but must be greater than or equal to 1  (in 'unknown file name' at line 6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pystan\\model.py\u001b[0m in \u001b[0;36mvb\u001b[1;34m(self, data, pars, iter, seed, init, sample_file, diagnostic_file, verbose, algorithm, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Algorithm must be one of {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m         \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m         \u001b[0mm_pars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m         \u001b[0mp_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mstanfit4anon_model_47fb036e992c954f28293ae82a359042_7670231639174555707.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_47fb036e992c954f28293ae82a359042_7670231639174555707.StanFit4Model.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception: anon_model_47fb036e992c954f28293ae82a359042_namespace::anon_model_47fb036e992c954f28293ae82a359042: I is 0, but must be greater than or equal to 1  (in 'unknown file name' at line 6)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create Stan model object\n",
    "sm = pystan.StanModel(model_code=model_definition)\n",
    "fit = sm.vb(data=data, iter=10000, algorithm=\"meanfield\", grad_samples=10, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the posterior distributions of some of the parameters of our model (you may have called these variables something else...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-ed2ed6d5f844>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpystan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvb_plot_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mu_prior\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#mu_prior\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Hyper-priors for each class for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "pystan_utils.vb_plot_variables(fit, \"mu_prior\") #mu_prior\n",
    "# Hyper-priors for each class for all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pystan_utils.vb_plot_variables(fit, \"sigma_prior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the inferred posteriors to make predictions. Lets first use the \"pystan_utils\" package to extract the expected values of the posterior distribution of the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fitted parameters\n",
    "mu_prior = pystan_utils.vb_extract_variable(fit, \"mu_prior\", var_type=\"vector\")\n",
    "sigma_prior = pystan_utils.vb_extract_variable(fit, \"sigma_prior\", var_type=\"vector\")\n",
    "alpha = pystan_utils.vb_extract_variable(fit, \"alpha\", var_type=\"matrix\", dims=(C,I))\n",
    "beta = pystan_utils.vb_extract_variable(fit, \"beta\", var_type=\"matrix\", dims=(C,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using expected values of the parameters, we can make predictions for the testset. However, we need to account for the fact that we now have different bias parameters per-individual, and adapt the code for making predictions accordingly. Make sure that you understand the code below. As always, if something is not 100% clear, ask! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test set\n",
    "y_hat = alpha[:,ind_test-1] + np.dot(beta, X_test.T)\n",
    "y_hat = np.argmax(y_hat, axis=0) + 1\n",
    "print(\"predictions:\", y_hat)\n",
    "print(\"true values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that is a signficant improvement, right? We improved the accuracy of our model from 67.9% to about 78.4%! (Hopefully you were able to obtain a similar or even better result :-)\n",
    "\n",
    "Did you see how your prior knowledge about the problem can make a substantial difference when building a model for it? This is how things are done in the model-based machine learning approach!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the posterior distributions inferred by STAN, we can even analyse the biases of different individuals identified by our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(I):\n",
    "    print(i, alpha[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps a histogram allows for a better global analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of biases towards mode 4 (car)\n",
    "plt.hist(alpha[3,:])\n",
    "plt.title(\"Biases towards mode 4\")\n",
    "plt.xlabel(\"alpha[4]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that, for most individuals the biases is around 0. However, we can also see that a few individuals really love their cars!\n",
    "\n",
    "Reflection exercise: can you think of ways in which you could use this model to try to identify policies (e.g. price changes or making terminals more efficient) that would allow to shift people's travel mode choices away from the car (e.g. towards public transport)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
