{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christian Arendt Rasmussen s144466, Frederikke Lehmann s154109 & Clara Foss s154312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Music Genre - Multiclass logistic baseline model and hierarchical logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this project in the course 42186 Model-based machine learning F19 , we have chosen to work with data from Spotify. We have extracted the data ourselves using the Spotipy Python library inspired by the Kaggle data set (https://www.kaggle.com/nadintamer/top-tracks-of-2017/version/1). We have around 23000 observations (filtering dublets with reduce this dramatically), consisting of random tracks from the genres \"pop\", \"metal\", \"classical\" and \"rap\", respectively. Each song has a set of audio features, including popularity danceability, energy, tempo, key, etc., and this leads us to our research question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research question\n",
    "How can audio features be used to predict the genre of a track?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import pystan\n",
    "import pystan_utils\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(42)\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (6, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### pop = 1 ####\n",
    "pop1 = pd.read_csv(\"SpotifyAudioFeatures2017.csv\")\n",
    "pop2 = pd.read_csv(\"SpotifyAudioFeatures2018.csv\")\n",
    "pop3 = pd.read_csv(\"SpotifyAudioFeatures2019.csv\")\n",
    "df_pop = pd.concat([pop1, pop2,pop3])\n",
    "df_pop[\"genre\"] = [1]*len(df_pop)\n",
    "\n",
    "#### metal = 2 ####\n",
    "met1 = pd.read_csv(\"SpotifyAudioFeatures2017metal.csv\")\n",
    "met2 = pd.read_csv(\"SpotifyAudioFeatures2018metal.csv\")\n",
    "met3 = pd.read_csv(\"SpotifyAudioFeatures2019metal.csv\")\n",
    "df_met = pd.concat([met1, met2, met3])\n",
    "#df_met = pd.read_csv(\"SpotifyAudioFeatures201720182019metal.csv\")\n",
    "df_met[\"genre\"] = [2]*len(df_met)\n",
    "\n",
    "#### classical = 3 ####\n",
    "df_clas = pd.read_csv(\"SpotifyAudioFeaturesclassical.csv\")\n",
    "df_clas[\"genre\"] = [3]*len(df_clas)\n",
    "\n",
    "#### rap = 4 ####\n",
    "rap1 = pd.read_csv(\"SpotifyAudioFeatures2017rap.csv\")\n",
    "rap2 = pd.read_csv(\"SpotifyAudioFeatures2018rap.csv\")\n",
    "rap3 = pd.read_csv(\"SpotifyAudioFeatures2019rap.csv\")\n",
    "df_rap = pd.concat([rap1, rap2, rap3])\n",
    "#df_rap = pd.read_csv(\"SpotifyAudioFeatures201720182019rap.csv\")\n",
    "df_rap[\"genre\"] = [4]*len(df_rap)\n",
    "\n",
    "df = pd.concat([df_rap,df_met,df_clas,df_pop])\n",
    "#df.to_csv(\"genredata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pop (1):  (6018, 19)\n",
      "Shape of metal (2):  (6010, 19)\n",
      "Shape of classical (3):  (5040, 19)\n",
      "Shape of rap (4):  (5928, 19)\n",
      "Total number of observations:  22996\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of pop (1): \", df_pop.shape)\n",
    "print(\"Shape of metal (2): \", df_met.shape)\n",
    "print(\"Shape of classical (3): \", df_clas.shape) \n",
    "print(\"Shape of rap (4): \",df_rap.shape)\n",
    "print(\"Total number of observations: \", df_pop.shape[0]+df_met.shape[0]+df_clas.shape[0]+df_rap.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Metro Boomin</td>\n",
       "      <td>Up To Something (feat. Travis Scott &amp; Young Thug)</td>\n",
       "      <td>4RGacGFT2ztXhGgzeaYzIR</td>\n",
       "      <td>66</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>0.799</td>\n",
       "      <td>184360</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>-8.809</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>114.014</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bryson Tiller</td>\n",
       "      <td>Run Me Dry</td>\n",
       "      <td>5GG3knKdxKWrNboRijxeKF</td>\n",
       "      <td>70</td>\n",
       "      <td>0.3930</td>\n",
       "      <td>0.646</td>\n",
       "      <td>169267</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>9</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>-9.017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>193.881</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Denzel Curry</td>\n",
       "      <td>SUPER SAIYAN SUPERMAN | ZUPER ZA1YAN ZUPERMAN</td>\n",
       "      <td>3HXSQWIyz7CUEI96kUurwn</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.760</td>\n",
       "      <td>132813</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-7.128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>142.035</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Joey Bada$$</td>\n",
       "      <td>TEMPTATION</td>\n",
       "      <td>7L9g4cPfohScjJ8mGwLQWr</td>\n",
       "      <td>70</td>\n",
       "      <td>0.3970</td>\n",
       "      <td>0.775</td>\n",
       "      <td>244198</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>-5.339</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>104.979</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Offset</td>\n",
       "      <td>Legacy (feat. Travis Scott &amp; 21 Savage)</td>\n",
       "      <td>7pMRoGLEJuFM2wl5pt0R99</td>\n",
       "      <td>85</td>\n",
       "      <td>0.1780</td>\n",
       "      <td>0.844</td>\n",
       "      <td>244941</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>-8.769</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>128.085</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    artist_name  \\\n",
       "0           0   Metro Boomin   \n",
       "1           1  Bryson Tiller   \n",
       "2           2   Denzel Curry   \n",
       "3           3    Joey Bada$$   \n",
       "4           4         Offset   \n",
       "\n",
       "                                          track_name                track_id  \\\n",
       "0  Up To Something (feat. Travis Scott & Young Thug)  4RGacGFT2ztXhGgzeaYzIR   \n",
       "1                                         Run Me Dry  5GG3knKdxKWrNboRijxeKF   \n",
       "2      SUPER SAIYAN SUPERMAN | ZUPER ZA1YAN ZUPERMAN  3HXSQWIyz7CUEI96kUurwn   \n",
       "3                                         TEMPTATION  7L9g4cPfohScjJ8mGwLQWr   \n",
       "4            Legacy (feat. Travis Scott & 21 Savage)  7pMRoGLEJuFM2wl5pt0R99   \n",
       "\n",
       "   popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "0          66        0.3190         0.799       184360   0.616   \n",
       "1          70        0.3930         0.646       169267   0.756   \n",
       "2          63        0.0543         0.760       132813   0.715   \n",
       "3          70        0.3970         0.775       244198   0.707   \n",
       "4          85        0.1780         0.844       244941   0.513   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
       "0          0.000000    1    0.1340    -8.809     1       0.1570  114.014   \n",
       "1          0.000032    9    0.2020    -9.017     0       0.4870  193.881   \n",
       "2          0.000009    1    0.1190    -7.128     1       0.0428  142.035   \n",
       "3          0.000000   10    0.8740    -5.339     0       0.1520  104.979   \n",
       "4          0.000000    1    0.0845    -8.769     1       0.3350  128.085   \n",
       "\n",
       "   time_signature  valence  genre  \n",
       "0               4   0.6670      4  \n",
       "1               4   0.5960      4  \n",
       "2               4   0.0479      4  \n",
       "3               4   0.7800      4  \n",
       "4               4   0.3440      4  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv\n",
    "df_tracks = pd.read_csv(\"genredata.csv\")\n",
    "df_tracks = df\n",
    "#df_tracks = df_tracks.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)\n",
    "df_tracks = df_tracks.dropna(axis = 0)\n",
    "df_tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing data - removing duplicated songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after filtering:  (13200, 19)\n"
     ]
    }
   ],
   "source": [
    "#df_tracks = shuffle(df_tracks)\n",
    "grouped = df_tracks.groupby(['artist_name','track_name'], as_index=True).size()\n",
    "#grouped[grouped > 1].count()\n",
    "df_tracks.drop_duplicates(subset=['artist_name','track_name'], inplace=True)\n",
    "\n",
    "# doing the same grouping as before to verify the solution\n",
    "grouped_after_dropping = df_tracks.groupby(['artist_name','track_name'], as_index=True).size()\n",
    "#grouped_after_dropping[grouped_after_dropping > 1].count()\n",
    "\n",
    "df_tracks[df_tracks.duplicated(subset=['artist_name','track_name'],keep=False)].count()\n",
    "df = df_tracks\n",
    "#df = shuffle(df)\n",
    "print(\"Shape after filtering: \", df.shape)\n",
    "#ind = df[\"Unnamed: 0\"]\n",
    "#df.to_csv(\"genredata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have a look at this preprocessing again, because there are too many duplicates in the pop-genre..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with dataset \"genredata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"genredata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['genre'])\n",
    "plt.ylabel('Count')\n",
    "plt.title('Genre frequency')\n",
    "plt.xticks(np.arange(1,5,step=1),[\"Pop\",\"Metal\",\"Classical\",\"Rap\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset to make model less time-consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)\n",
    "df = df[:200]\n",
    "# separate between features/inputs (X) and target/output variables (y)\n",
    "mat = df.drop(['artist_name','track_name','track_id','Unnamed: 0.1'],axis = 1)\n",
    "mat = mat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "        12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,\n",
       "        23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,\n",
       "        34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,\n",
       "        45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,\n",
       "        56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,  66.,\n",
       "        67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,  77.,\n",
       "        78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,\n",
       "        89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99.,\n",
       "       100., 101., 102., 103., 104., 105., 106., 107., 108., 109., 110.,\n",
       "       111., 112., 113., 114., 115., 116., 117., 118., 119., 120., 121.,\n",
       "       122., 123., 124., 125., 126., 127., 128., 129., 130., 131., 132.,\n",
       "       133., 134., 135., 136., 137., 138., 139., 140., 141., 142., 143.,\n",
       "       144., 145., 146., 147., 148., 149., 150., 151., 152., 153., 154.,\n",
       "       155., 156., 157., 158., 159., 160., 161., 162., 163., 164., 165.,\n",
       "       166., 167., 168., 169., 170., 171., 172., 173., 174., 175., 176.,\n",
       "       177., 178., 179., 180., 181., 182., 183., 184., 185., 186., 187.,\n",
       "       188., 189., 190., 191., 192., 193., 194., 195., 196., 197., 198.,\n",
       "       199., 200.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re-enumrate track ids\n",
    "i = 0\n",
    "for i in range(len(mat)):\n",
    "    mat[i,0] = i+1\n",
    "mat[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass logistic baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is inspired by Lecture 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 14)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "X = mat[:,1:-1].astype(\"float\")\n",
    "print(X.shape)\n",
    "y = mat[:,-1].astype(\"int\")\n",
    "print(y.shape)\n",
    "ind = mat[:,0].astype(\"int\")\n",
    "\n",
    "# standardize input features\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 160\n",
      "num test: 40\n"
     ]
    }
   ],
   "source": [
    "train_perc = 0.8 # percentage of training data\n",
    "split_point = int(train_perc*len(y))\n",
    "perm = np.random.permutation(len(y))\n",
    "ix_train = perm[:split_point]\n",
    "ix_test = perm[split_point:]\n",
    "X_train = X[ix_train,:]\n",
    "X_test = X[ix_test,:]\n",
    "ind_train = ind[ix_train]\n",
    "ind_test = ind[ix_test]\n",
    "y_train = y[ix_train]\n",
    "y_test = y[ix_test]\n",
    "print(\"num train: %d\" % len(y_train))\n",
    "print(\"num test: %d\" % len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [3 4 3 2 4 3 4 3 4 3 3 4 4 3 4 3 4 4 2 3 4 4 3 3 3 3 4 4 4 4 2 3 4 3 2 3 3\n",
      " 3 3 3]\n",
      "True values: [3 4 3 2 4 3 4 3 4 3 3 2 4 3 2 3 4 2 4 3 2 4 3 3 3 3 4 4 2 4 4 3 2 3 4 3 3\n",
      " 3 2 3]\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# create and fit logistic regression model\n",
    "logreg = linear_model.LogisticRegression(solver='lbfgs', multi_class='ovr')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test set\n",
    "y_hat = logreg.predict(X_test)\n",
    "print(\"Predictions:\", y_hat)\n",
    "print(\"True values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical logistic regression in STAN\n",
    "\n",
    "Our dataset consists of multiple observations from various tracks. However, when we build our original logistic regression in STAN, our specification assumes that all tracks share a unique set of bias (alpha) coefficients (beta). In other words, this is equivalent to assuming, for example, that all tracks are equally biased towards a given genre (e.g. pop). This is obviously a very strong assumption. We should allow different tracks to have different biases (alpha).\n",
    "\n",
    "This can be done by placing a hierarchical prior on the intercepts (alpha). The generative process then becomes:\n",
    "\n",
    "1. For each class $c \\in \\{1,\\dots,C\\}$\n",
    "    2. Draw global mean parameters $\\mu_c \\sim \\mathcal{N}(0,10)$\n",
    "    3. Draw global variance parameters $\\sigma_c \\sim \\mbox{Cauchy}(0,10)$\n",
    "    5. For each track $i \\in \\{1,\\dots,I\\}$\n",
    "        4. Draw $\\beta_{i,c}$ such that $\\beta_{i,c} \\sim \\mathcal{N}(\\mu_c,\\sigma_c)$\n",
    "    6. For each track $i \\in \\{1,\\dots,I\\}$\n",
    "        5. Draw $\\alpha_{i,c}$ such that $\\alpha_{i,c} \\sim \\mathcal{N}(\\mu_c,\\sigma_c)$\n",
    "\n",
    "6. For each data point $n=\\{1,\\dots,N\\}$\n",
    "    7. Draw target class $y_n \\sim \\mbox{Multinomial}(\\mbox{Softmax}(\\textbf{x}_n,\\boldsymbol\\alpha_{i_n},\\boldsymbol\\beta_1,\\dots,\\boldsymbol\\beta_C))$\n",
    "    \n",
    "where $i_n$ is the track identifier for track $n$, and $\\boldsymbol\\mu=\\{\\mu_1\\dots\\mu_C\\}$ and $\\boldsymbol\\sigma=\\{\\sigma_1\\dots\\sigma_C\\}$.\n",
    "\n",
    "(This needs to be revised, as we are unsure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Stan model\n",
    "model_definition = \"\"\"\n",
    "data {\n",
    "    int<lower = 1> N;\n",
    "    int<lower = 1> D;\n",
    "    int<lower = 1> C;\n",
    "    int<lower = 1> I;\n",
    "    int ind[N];\n",
    "    matrix[N,D] X;\n",
    "    int<lower=1,upper=C> y[N];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    vector<lower=1>[C] mu_prior;\n",
    "    vector<lower=1>[C] sigma_prior;\n",
    "    \n",
    "    matrix[I,C] alpha;\n",
    "    matrix[C,D] beta;  \n",
    "    \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "model {\n",
    "    for (c in 1:C) {\n",
    "        mu_prior[c] ~ normal(c,0.5);\n",
    "        sigma_prior[c] ~ cauchy(c,0.5);\n",
    "        \n",
    "        beta[c,1] ~ beta(0,1); //popularity\n",
    "        beta[c,2] ~ beta(0,1); //acousticness\n",
    "        beta[c,3] ~ beta(0,1); //danceability\n",
    "        beta[c,4] ~ normal(0,10); //duration\n",
    "        beta[c,5] ~ beta(0,1); //energy\n",
    "        beta[c,6] ~ beta(0,1); //instrumentalness\n",
    "        beta[c,7] ~ normal(0,10); //key - should be categorical...\n",
    "        beta[c,8] ~ normal(0.1,0.2); //liveness\n",
    "        beta[c,9] ~ normal(0,10); //loudness\n",
    "        beta[c,10] ~ normal(0,10); //mode - should be binomial...\n",
    "        beta[c,11] ~ normal(0.1,0.2); //speechiness\n",
    "        beta[c,12] ~ normal(0,10); //tempo\n",
    "        beta[c,13] ~ beta(0,1); //time_signature\n",
    "        beta[c,14] ~ normal(0.4,0.8); //valence\n",
    "        \n",
    "        \n",
    "        for (i in 1:I){\n",
    "            alpha[i,c] ~ normal(mu_prior[c],sigma_prior[c]);\n",
    "        }\n",
    "    }\n",
    "    for (n in 1:N){\n",
    "        y[n] ~ categorical(softmax(alpha[ind[n],:]' + beta * X[n]'));\n",
    "        \n",
    "    }    \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions regarding the model...\n",
    "\n",
    "1. Do we set different mu and sigma for each class C? We observed that different mu for each class results in a higher accuracy (we get approximately +8% accuracy doing this...) \n",
    "2. How do we define beta parameters? \n",
    "3. How do we find a proper distribution for e.g. popularity (which is a mixture of exponential/normal)?\n",
    "4. How do we make distributions dependent on other distributions? \n",
    "5. We cant make beta[c,10] follow a binomial distribution because it expects beta to be an int (it is real in this case...). \n",
    "6. When compiling the model, we get the error: \"Initialization between (-2, 2) failed after 100 attempts. Try specifying initial values, reducing ranges of constrained values, or reparameterizing the model.\". How does one fix this? \n",
    "7. Why do we standardize the data? And should we make priors for the standardized data (or how is looked before)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input data for STAN, compile STAN program and run inference using ADVI (much faster in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=160, D=14, C=4, I=200\n"
     ]
    }
   ],
   "source": [
    "# prepare data for Stan model\n",
    "N, D = X_train.shape\n",
    "C = int(y_train.max())\n",
    "I = ind.max()\n",
    "print(\"N=%d, D=%d, C=%d, I=%d\" % (N,D,C,I))\n",
    "data = {'N': N, 'D': D, 'C': C, 'I':I, 'ind':ind_train, 'X': X_train, 'y': y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_54e549058982fafbe69d7cde806887cf NOW.\n",
      "C:\\Users\\clara\\Anaconda3\\lib\\site-packages\\Cython\\Compiler\\Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\clara\\AppData\\Local\\Temp\\tmp_2hki7xk\\stanfit4anon_model_54e549058982fafbe69d7cde806887cf_3408306645541388630.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "C:\\Users\\clara\\Anaconda3\\lib\\site-packages\\pystan\\misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Initialization failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pystan\\model.py\u001b[0m in \u001b[0;36mvb\u001b[1;34m(self, data, pars, iter, seed, init, sample_file, diagnostic_file, verbose, algorithm, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[0mstan_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_valid_stan_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstan_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_sampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstan_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Automatic Differentiation Variational Inference (ADVI) is an EXPERIMENTAL ALGORITHM.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mstanfit4anon_model_54e549058982fafbe69d7cde806887cf_3408306645541388630.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_54e549058982fafbe69d7cde806887cf_3408306645541388630.StanFit4Model._call_sampler\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mstanfit4anon_model_54e549058982fafbe69d7cde806887cf_3408306645541388630.pyx\u001b[0m in \u001b[0;36mstanfit4anon_model_54e549058982fafbe69d7cde806887cf_3408306645541388630._call_sampler\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Initialization failed."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create Stan model object\n",
    "sm = pystan.StanModel(model_code=model_definition)\n",
    "fit = sm.vb(data=data, iter=10000, algorithm=\"meanfield\", grad_samples=10, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-aec4a948ad7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpystan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvb_plot_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mu_prior\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "pystan_utils.vb_plot_variables(fit, \"mu_prior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-1f961bd0e1ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpystan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvb_plot_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sigma_prior\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "pystan_utils.vb_plot_variables(fit, \"sigma_prior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions using pystan_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the inferred posteriors to make predictions. Extracting the expected values of the posterior distribution of the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-63b24da7c29d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get fitted parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmu_prior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvb_extract_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mu_prior\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"vector\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msigma_prior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvb_extract_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sigma_prior\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"vector\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvb_extract_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"alpha\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"matrix\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpystan_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvb_extract_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"beta\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"matrix\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "# get fitted parameters\n",
    "mu_prior = pystan_utils.vb_extract_variable(fit, \"mu_prior\", var_type=\"vector\")\n",
    "sigma_prior = pystan_utils.vb_extract_variable(fit, \"sigma_prior\", var_type=\"vector\")\n",
    "alpha = pystan_utils.vb_extract_variable(fit, \"alpha\", var_type=\"matrix\", dims=(C,I))\n",
    "beta = pystan_utils.vb_extract_variable(fit, \"beta\", var_type=\"matrix\", dims=(C,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using expected values of the parameters, we can make predictions for the testset. However, we need to account for the fact that we now have different bias parameters per track. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-a39c1d172766>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# make predictions for test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind_test\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predictions:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"true values:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "# make predictions for test set\n",
    "y_hat = alpha[:,ind_test-1] + np.dot(beta, X_test.T)\n",
    "y_hat = np.argmax(y_hat, axis=0) + 1\n",
    "print(\"predictions:\", y_hat)\n",
    "print(\"true values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working model with wrong hyper-priors...\n",
    "Below is a working model in STAN with accuracy around 80% but with the wrong hyper-priors because the model fails otherwise..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Stan model\n",
    "model_definition = \"\"\"\n",
    "data {\n",
    "    int<lower = 1> N;\n",
    "    int<lower = 1> D;\n",
    "    int<lower = 1> C;\n",
    "    int<lower = 1> I;\n",
    "    int ind[N];\n",
    "    matrix[N,D] X;\n",
    "    int<lower=1,upper=C> y[N];\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    vector<lower=1>[C] mu_prior;\n",
    "    vector<lower=1>[C] sigma_prior;\n",
    "    \n",
    "    matrix[I,C] alpha;\n",
    "    matrix[C,D] beta;  \n",
    "    \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "model {\n",
    "    for (c in 1:C) {\n",
    "        mu_prior[c] ~ normal(c,0.5);\n",
    "        sigma_prior[c] ~ normal(c,0.5);\n",
    "        \n",
    "        beta[c,1] ~ normal(0,0.5); //popularity\n",
    "        beta[c,2] ~ normal(0.5,0.5); //acousticness\n",
    "        beta[c,3] ~ normal(0.5,0.25); //danceability\n",
    "        beta[c,4] ~ cauchy(0,0.5); //duration\n",
    "        beta[c,5] ~ normal(0,0.5); //energy\n",
    "        beta[c,6] ~ cauchy(0,1); //instrumentalness\n",
    "        beta[c,7] ~ normal(0,0.5); //key\n",
    "        beta[c,8] ~ cauchy(0.1,0.2); //liveness\n",
    "        beta[c,9] ~ cauchy(0,0.5); //loudness\n",
    "        beta[c,10] ~ normal(0.5,0.5); //mode\n",
    "        beta[c,11] ~ cauchy(0.1,0.2); //speechiness\n",
    "        beta[c,12] ~ normal(120,50); //tempo\n",
    "        beta[c,13] ~ normal(0,0.5); //time_signature\n",
    "        beta[c,14] ~ cauchy(0.4,0.8); //valence\n",
    "        \n",
    "        \n",
    "        for (i in 1:I){\n",
    "            alpha[i,c] ~ normal(mu_prior[c],sigma_prior[c]);\n",
    "        }\n",
    "    }\n",
    "    for (n in 1:N){\n",
    "        y[n] ~ categorical(softmax(alpha[ind[n],:]' + beta * X[n]'));\n",
    "        \n",
    "    }    \n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=160, D=14, C=4, I=200\n"
     ]
    }
   ],
   "source": [
    "# prepare data for Stan model\n",
    "N, D = X_train.shape\n",
    "C = int(y_train.max())\n",
    "I = ind.max()\n",
    "print(\"N=%d, D=%d, C=%d, I=%d\" % (N,D,C,I))\n",
    "data = {'N': N, 'D': D, 'C': C, 'I':I, 'ind':ind_train, 'X': X_train, 'y': y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_c7f3a42cecfb931cfe1c3618dfa44a70 NOW.\n",
      "C:\\Users\\clara\\Anaconda3\\lib\\site-packages\\Cython\\Compiler\\Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\clara\\AppData\\Local\\Temp\\tmpbzaj4stx\\stanfit4anon_model_c7f3a42cecfb931cfe1c3618dfa44a70_930758808550432825.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "WARNING:pystan:Automatic Differentiation Variational Inference (ADVI) is an EXPERIMENTAL ALGORITHM.\n",
      "WARNING:pystan:ADVI samples may be found on the filesystem in the file `C:\\Users\\clara\\AppData\\Local\\Temp\\tmpufpwl4p4\\output.csv`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create Stan model object\n",
    "sm = pystan.StanModel(model_code=model_definition)\n",
    "fit = sm.vb(data=data, iter=10000, algorithm=\"meanfield\", grad_samples=10, seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-a39c1d172766>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# make predictions for test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind_test\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predictions:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"true values:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'alpha' is not defined"
     ]
    }
   ],
   "source": [
    "# make predictions for test set\n",
    "y_hat = alpha[:,ind_test-1] + np.dot(beta, X_test.T)\n",
    "y_hat = np.argmax(y_hat, axis=0) + 1\n",
    "print(\"predictions:\", y_hat)\n",
    "print(\"true values:\", y_test)\n",
    "\n",
    "# evaluate prediction accuracy\n",
    "print(\"Accuracy:\", 1.0*np.sum(y_hat == y_test) / len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
